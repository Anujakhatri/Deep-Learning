{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7ba2789-8881-4ad5-952d-1f993c993fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "462f096a-c0bb-40d0-b39b-5f21fddff11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76badfaf-84c4-4fc9-9aa9-499c85dbd3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c65e091-a156-448c-b7e5-f148805a296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71106506-5973-4620-8ab4-111949680615",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "185e8a1a-06da-40eb-897d-419b02b32648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32040a70-31d6-4e4e-987f-864e0477aa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'image label = [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[5])\n",
    "plt.title(f\"image label = {y_train[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fe4be0a-b172-4d87-880d-d2dbc17a645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b9fdeee-c990-4aa9-91a4-8c3abe09c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de0aa4bc-1e18-403f-b8af-24d046f237ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb720178-3022-45de-8620-7d39eb7ae0a7",
   "metadata": {},
   "source": [
    "# Dense = Fully Feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f10b86e0-9242-4820-ab13-34caaf1abb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape =(28,28)), #input layer neuron 784\n",
    "    Dense(5,activation = 'relu'), #hidden layer \n",
    "    Dense(10, activation = 'softmax') #output layer 10 neuron\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b05033b5-5214-4e13-9875-1afef87ec153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 3925      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                60        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,985\n",
      "Trainable params: 3,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f967ed7-6e0b-41e8-a67f-ee08159fad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ddbd261-5bc2-493a-9e4e-95ba0aa84c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'fif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfif\u001b[49m(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'fif'"
     ]
    }
   ],
   "source": [
    "model.fif(x_train, y_train, epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93605a66-7ffd-467e-9250-891a67bab749",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py:3685\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3680\u001b[0m     \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3681\u001b[0m     \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3682\u001b[0m     \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   3683\u001b[0m     \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3685\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   3686\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3687\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3689\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "147c3ab3-11c8-4ac2-8313-9b396a1a8097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25c9a715-a470-46e3-baf3-ac8b5d840bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.01771817, -0.05384657,  0.02899608, -0.03262835,  0.07543518],\n",
       "        [ 0.01888511,  0.06793316,  0.02326259,  0.01858621,  0.03222271],\n",
       "        [-0.03546465, -0.05989684,  0.0089383 , -0.00880374,  0.08185534],\n",
       "        ...,\n",
       "        [-0.00987422, -0.01830281, -0.02131219, -0.03873912,  0.0870818 ],\n",
       "        [-0.04312818, -0.08367423, -0.00070043, -0.08473996,  0.02667912],\n",
       "        [-0.04407571, -0.06195617, -0.0204671 ,  0.00636045,  0.00512529]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.06912839,  0.58421105,  0.20520973, -0.0496282 , -0.2035904 ,\n",
       "         -0.5649842 , -0.03691572,  0.25277525, -0.02039695,  0.11057401],\n",
       "        [ 0.46206707,  0.58275515, -0.47022372,  0.57106906,  0.58923155,\n",
       "         -0.54451287,  0.2538051 ,  0.25692964,  0.09743619,  0.2019813 ],\n",
       "        [ 0.48085624,  0.6027128 ,  0.4909386 ,  0.5738813 ,  0.02387744,\n",
       "          0.5281361 ,  0.470349  ,  0.1976211 , -0.13018185,  0.26520103],\n",
       "        [-0.51481557,  0.44769484,  0.27797812, -0.1052193 ,  0.52342874,\n",
       "         -0.17564222, -0.03542912, -0.04064023, -0.22006139, -0.01176077],\n",
       "        [ 0.02594358, -0.14910182, -0.36868474, -0.31706825, -0.23601335,\n",
       "          0.14738148,  0.42142373, -0.2484411 ,  0.21576798,  0.10631692]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754fb3f0-c689-4d0a-b0dc-24bd3626f8e2",
   "metadata": {},
   "source": [
    "# Try do deal with complex neural network\n",
    "           Input Layer\n",
    "                 |\n",
    "         -------------------\n",
    "         |                 |\n",
    "     Hidden Layer 1    Hidden Layer 2\n",
    "         |                  /\n",
    "         |                 /\n",
    "         |                /\n",
    "        H1a              /\n",
    "          \\             /\n",
    "           \\           /\n",
    "            \\         /\n",
    "             \\       /\n",
    "              \\     /\n",
    "               \\   /\n",
    "                \\ /\n",
    "             Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "700974aa-ff23-4d0e-8b6e-867a0f99bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7875e2aa-688f-48d4-96f6-70f46841b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "<>:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "/var/folders/8h/r_3bcb_177x5qbpxcsfynp_80000gn/T/ipykernel_7201/3853797872.py:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  flatten= Flatten(input_shape=(28,28)(input_layer))\n",
      "/var/folders/8h/r_3bcb_177x5qbpxcsfynp_80000gn/T/ipykernel_7201/3853797872.py:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  flatten= Flatten(input_shape=(28,28)(input_layer))\n",
      "/var/folders/8h/r_3bcb_177x5qbpxcsfynp_80000gn/T/ipykernel_7201/3853797872.py:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  flatten= Flatten(input_shape=(28,28)(input_layer))\n",
      "/var/folders/8h/r_3bcb_177x5qbpxcsfynp_80000gn/T/ipykernel_7201/3853797872.py:2: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  flatten= Flatten(input_shape=(28,28)(input_layer))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m flatten\u001b[38;5;241m=\u001b[39m Flatten(input_shape\u001b[38;5;241m=\u001b[39m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape= (28,28))\n",
    "flatten= Flatten(input_shape=(28,28)(input_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d731e15-2845-4e61-ab5d-a5e34053a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1= Dense(128, activation ='relu')(input_layer)\n",
    "hidden2= Dense(168, activation ='relu')(input_layer)\n",
    "hidden11= Dense(64, activation ='relu')(hidden1)\n",
    "merge = concatenate([hidden11, hidden2])\n",
    "output_layer= Dense(10, activation='softmax')(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a086945f-b0a8-478c-b0c8-1a87995dd8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs =input_layer, outputs= output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afe84cf6-6c43-431b-8176-bd7433e01568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 28, 128)      3712        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 28, 64)       8256        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 28, 168)      4872        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 232)      0           ['dense_8[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 28, 10)       2330        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,170\n",
      "Trainable params: 19,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff5bf4bb-4521-426d-8349-19e70176e9c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydot' has no attribute 'InvocationException'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pydot/core.py:1826\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1826\u001b[0m     stdout_data, stderr_data, process \u001b[38;5;241m=\u001b[39m \u001b[43mcall_graphviz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m        \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1830\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pydot/core.py:249\u001b[0m, in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m program_with_args \u001b[38;5;241m=\u001b[39m [program] \u001b[38;5;241m+\u001b[39m arguments\n\u001b[0;32m--> 249\u001b[0m process \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogram_with_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworking_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m stdout_data, stderr_data \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/subprocess.py:1837\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1836\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/vis_utils.py:57\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Attempt to create an image of a blank graph\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# to check the pydot/graphviz installation.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/pydot/core.py:1835\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprog\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found in path.\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1835\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/vis_utils.py:451\u001b[0m, in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations, show_trainable)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     )\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_graphviz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    452\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install pydot (`pip install pydot`) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand install graphviz \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor plot_model to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m     )\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython.core.magics.namespace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;66;03m# We don't raise an exception here in order to avoid crashing\u001b[39;00m\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;66;03m# notebook tests where graphviz is not available.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/vis_utils.py:59\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     pydot\u001b[38;5;241m.\u001b[39mDot\u001b[38;5;241m.\u001b[39mcreate(pydot\u001b[38;5;241m.\u001b[39mDot())\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInvocationException\u001b[49m):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pydot' has no attribute 'InvocationException'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0af7e5-86a1-4da9-823c-b234906a500b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
